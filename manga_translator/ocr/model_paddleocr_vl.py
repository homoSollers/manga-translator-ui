"""
PaddleOCR-VL for Manga OCR Model

基于 PaddleOCR-VL 的漫画文字识别模型
模型来源: https://huggingface.co/jzhang533/PaddleOCR-VL-For-Manga
"""

import os
import sys
import numpy as np
from typing import List
from PIL import Image

import cv2
import einops
import torch

from .common import OfflineOCR
from ..config import OcrConfig
from ..utils import Quadrilateral
from ..utils.generic import AvgMeter


class ModelPaddleOCRVL(OfflineOCR):
    """
    PaddleOCR-VL for Manga OCR 模型

    这是一个基于 VLM 的 OCR 模型，专门针对日本漫画进行了微调。
    模型使用 transformers 库加载，支持 GPU 加速。
    """

    _MODEL_MAPPING = {
        'model': {
            'url': [
                'https://www.modelscope.cn/models/hgmzhn/manga-translator-ui/resolve/master/paddleocr_vl.7z',
            ],
            'hash': 'a84de910b06126af371c8092396f2943b99cbd6cf9a20fa88dd432ef74ded674',
            'archive': {
                'paddleocr_vl/': '.',
            },
        },
        # 48px 颜色预测模型
        'color_model': {
            'url': [
                'https://github.com/zyddnys/manga-image-translator/releases/download/beta-0.3/ocr_ar_48px.ckpt',
                'https://www.modelscope.cn/models/hgmzhn/manga-translator-ui/resolve/master/ocr_ar_48px.ckpt',
            ],
            'hash': '29daa46d080818bb4ab239a518a88338cbccff8f901bef8c9db191a7cb97671d',
        },
        'color_dict': {
            'url': [
                'https://github.com/zyddnys/manga-image-translator/releases/download/beta-0.3/alphabet-all-v7.txt',
                'https://www.modelscope.cn/models/hgmzhn/manga-translator-ui/resolve/master/alphabet-all-v7.txt',
            ],
            'hash': 'f5722368146aa0fbcc9f4726866e4efc3203318ebb66c811d8cbbe915576538a',
        },
    }

    # 模型子目录名（在 models/ocr/ 下）
    MODEL_DIR_NAME = "paddleocr_vl"

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.model = None
        self.processor = None
        self.device = None
        self.color_model = None  # 48px 模型用于颜色预测

    async def _load(self, device: str):
        """加载模型"""
        # 动态导入，避免未使用时加载
        from transformers import AutoProcessor

        # 确定模型路径 - 使用 models/ocr/paddleocr_vl
        model_path = os.path.join(self.model_dir, self.MODEL_DIR_NAME)
        use_relative_path = False
        original_cwd = None

        if not os.path.exists(model_path) or not os.path.exists(os.path.join(model_path, "config.json")):
            # 如果本地没有，尝试从 HuggingFace 加载
            model_path = "jzhang533/PaddleOCR-VL-For-Manga"
            self.logger.info(f"本地模型不存在，使用 HuggingFace 模型: {model_path}")
        else:
            self.logger.info(f"使用本地模型: {model_path}")
            # Windows 中文路径兼容：sentencepiece 无法处理非 ASCII 路径
            # 通过切换工作目录使用相对路径来规避
            if sys.platform == 'win32':
                try:
                    # 检测路径是否包含非 ASCII 字符
                    model_path.encode('ascii')
                except UnicodeEncodeError:
                    use_relative_path = True
                    self.logger.info("检测到中文路径，使用相对路径加载模式")

        # 设置设备
        if device == 'cuda' and torch.cuda.is_available():
            self.device = 'cuda'
            self.use_gpu = True
            # 使用 bfloat16 以节省显存
            torch_dtype = torch.bfloat16
        elif device == 'mps' and hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            self.device = 'mps'
            self.use_gpu = True
            torch_dtype = torch.float16
        else:
            self.device = 'cpu'
            self.use_gpu = False
            torch_dtype = torch.float32

        self.logger.info(f"加载 PaddleOCR-VL 模型到 {self.device}...")

        try:
            # 如果需要使用相对路径，切换工作目录
            if use_relative_path:
                original_cwd = os.getcwd()
                os.chdir(model_path)
                load_path = "."
            else:
                load_path = model_path

            # 加载处理器和模型
            self.processor = AutoProcessor.from_pretrained(
                load_path,
                trust_remote_code=True,
                local_files_only=use_relative_path,
                use_fast=False
            )

            # 使用 AutoModel 加载自定义模型架构
            from transformers import AutoModel
            self.model = AutoModel.from_pretrained(
                load_path,
                trust_remote_code=True,
                torch_dtype=torch_dtype,
                device_map=self.device if self.device != 'cpu' else None,
                local_files_only=use_relative_path
            )
        finally:
            # 恢复原工作目录
            if original_cwd is not None:
                os.chdir(original_cwd)

        if self.device == 'cpu':
            self.model = self.model.to(self.device)

        self.model.eval()
        self.logger.info("PaddleOCR-VL 模型加载完成")

        # 加载 48px 模型用于颜色预测
        await self._load_color_model(device)

    async def _load_color_model(self, device: str):
        """加载 48px 颜色预测模型"""
        from .model_48px import OCR

        try:
            dict_48px_path = self._get_file_path('alphabet-all-v7.txt')
            ckpt_48px_path = self._get_file_path('ocr_ar_48px.ckpt')

            if os.path.exists(dict_48px_path) and os.path.exists(ckpt_48px_path):
                with open(dict_48px_path, 'r', encoding='utf-8') as fp:
                    dictionary_48px = [s[:-1] for s in fp.readlines()]

                self.color_model = OCR(dictionary_48px, 768)
                sd = torch.load(ckpt_48px_path, map_location='cpu', weights_only=False)

                # Handle PyTorch Lightning checkpoint format
                if 'state_dict' in sd:
                    sd = sd['state_dict']

                # Remove 'model.' prefix from keys if present
                cleaned_sd = {}
                for k, v in sd.items():
                    if k.startswith('model.'):
                        cleaned_sd[k[6:]] = v
                    else:
                        cleaned_sd[k] = v

                self.color_model.load_state_dict(cleaned_sd)
                self.color_model.eval()

                if device == 'cuda' or device == 'mps':
                    self.color_model = self.color_model.to(device)

                self.logger.info("48px 颜色预测模型已加载")
            else:
                self.logger.warning(f"48px 模型文件不存在: {dict_48px_path} 或 {ckpt_48px_path}")
                self.color_model = None
        except Exception as e:
            self.logger.warning(f"加载 48px 颜色模型失败: {e}")
            self.color_model = None

    async def _unload(self):
        """卸载模型"""
        if self.model is not None:
            del self.model
            self.model = None
        if self.processor is not None:
            del self.processor
            self.processor = None
        if self.color_model is not None:
            del self.color_model
            self.color_model = None
        if self.use_gpu:
            torch.cuda.empty_cache()
        self.logger.info("PaddleOCR-VL 模型已卸载")

    def _recognize_single(self, img: np.ndarray) -> str:
        """
        识别单个图像区域的文本

        Args:
            img: numpy 数组格式的图像 (RGB)

        Returns:
            识别的文本
        """
        # 转换为 PIL Image
        if isinstance(img, np.ndarray):
            pil_img = Image.fromarray(img)
        else:
            pil_img = img

        # 确保是 RGB 模式
        if pil_img.mode != 'RGB':
            pil_img = pil_img.convert('RGB')

        # 构建对话消息
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": pil_img},
                    {"type": "text", "text": "Please OCR this image."}
                ]
            }
        ]

        # 使用聊天模板
        text = self.processor.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )

        # 预处理
        inputs = self.processor(
            text=[text],
            images=[pil_img],
            return_tensors="pt",
            padding=True
        )

        # 移动到设备
        inputs = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}

        # 生成文本
        with torch.no_grad():
            generated_ids = self.model.generate(
                **inputs,
                max_new_tokens=256,
                do_sample=False
            )

        # 解码 - 只取新生成的部分
        input_len = inputs["input_ids"].shape[1]
        generated_ids_trimmed = generated_ids[:, input_len:]
        output_text = self.processor.batch_decode(
            generated_ids_trimmed,
            skip_special_tokens=True,
            clean_up_tokenization_spaces=False
        )[0]

        return output_text.strip()

    def _estimate_colors_48px(self, region: np.ndarray, textline: Quadrilateral):
        """使用 48px 模型预测前景色和背景色"""
        try:
            # 如果 48px 模型未加载，使用默认颜色
            if self.color_model is None:
                textline.fg_r = textline.fg_g = textline.fg_b = 0
                textline.bg_r = textline.bg_g = textline.bg_b = 255
                return

            # 调整大小到 48px 高度
            text_height = 48
            h, w = region.shape[:2]
            ratio = w / float(h)
            new_w = int(round(ratio * text_height))

            if new_w == 0:
                new_w = 1

            region_resized = cv2.resize(region, (new_w, text_height), interpolation=cv2.INTER_AREA)

            # 转换为 tensor
            image_tensor = (torch.from_numpy(region_resized).float() - 127.5) / 127.5
            image_tensor = einops.rearrange(image_tensor, 'H W C -> 1 C H W')

            # GPU 加速
            if self.use_gpu:
                image_tensor = image_tensor.to(self.device)

            # 使用 48px 模型推理
            with torch.no_grad():
                ret = self.color_model.infer_beam_batch(image_tensor, [new_w], beams_k=5, max_seq_length=255)

            if ret and len(ret) > 0:
                pred_chars_index, prob, fg_pred, bg_pred, fg_ind_pred, bg_ind_pred = ret[0]

                # 计算颜色
                has_fg = (fg_ind_pred[:, 1] > fg_ind_pred[:, 0])
                has_bg = (bg_ind_pred[:, 1] > bg_ind_pred[:, 0])

                fr = AvgMeter()
                fg = AvgMeter()
                fb = AvgMeter()
                br = AvgMeter()
                bg = AvgMeter()
                bb = AvgMeter()

                for chid, c_fg, c_bg, h_fg, h_bg in zip(pred_chars_index, fg_pred, bg_pred, has_fg, has_bg):
                    ch = self.color_model.dictionary[chid]
                    if ch == '<S>':
                        continue
                    if ch == '</S>':
                        break
                    # 处理前景色
                    if h_fg.item():
                        fr(int(c_fg[0] * 255))
                        fg(int(c_fg[1] * 255))
                        fb(int(c_fg[2] * 255))
                    # 处理背景色
                    if h_bg.item():
                        br(int(c_bg[0] * 255))
                        bg(int(c_bg[1] * 255))
                        bb(int(c_bg[2] * 255))
                    else:
                        # 如果没有背景色，使用前景色作为背景色
                        br(int(c_fg[0] * 255))
                        bg(int(c_fg[1] * 255))
                        bb(int(c_fg[2] * 255))

                textline.fg_r = min(max(int(fr()), 0), 255)
                textline.fg_g = min(max(int(fg()), 0), 255)
                textline.fg_b = min(max(int(fb()), 0), 255)
                textline.bg_r = min(max(int(br()), 0), 255)
                textline.bg_g = min(max(int(bg()), 0), 255)
                textline.bg_b = min(max(int(bb()), 0), 255)
            else:
                # 如果推理失败，设置默认颜色
                textline.fg_r = textline.fg_g = textline.fg_b = 0
                textline.bg_r = textline.bg_g = textline.bg_b = 255

        except Exception as e:
            # 如果出错，设置默认颜色
            textline.fg_r = textline.fg_g = textline.fg_b = 0
            textline.bg_r = textline.bg_g = textline.bg_b = 255
            self.logger.debug(f"48px 颜色预测失败: {e}")

    async def _infer(self, image: np.ndarray, textlines: List[Quadrilateral], config: OcrConfig, verbose: bool = False) -> List[Quadrilateral]:
        """
        推理主函数

        Args:
            image: 完整图像
            textlines: 检测到的文本行边界框
            config: OCR 配置
            verbose: 是否详细输出

        Returns:
            带有识别文本的 Quadrilateral 列表
        """
        text_height = 48  # 默认文本高度
        ignore_bubble = config.ignore_bubble

        # 生成文本方向信息
        quadrilaterals = list(self._generate_text_direction(textlines))

        output_regions = []

        for idx, (q, direction) in enumerate(quadrilaterals):
            # 获取变换后的区域图像
            region_img = q.get_transformed_region(image, direction, text_height)

            # 过滤非气泡区域
            if ignore_bubble > 0:
                if self._should_ignore_region(region_img, ignore_bubble, image, q):
                    self.logger.info(f'[FILTERED] Region {idx} ignored - Non-bubble area detected (ignore_bubble={ignore_bubble})')
                    continue

            try:
                # 识别文本
                text = self._recognize_single(region_img)

                if not text:
                    self.logger.info(f'[EMPTY] Region {idx} - No text detected')
                    q.text = ''
                    q.prob = 0.0
                else:
                    self.logger.info(f'[OCR] Region {idx}: {text}')
                    q.text = text
                    q.prob = 0.9  # VLM 模型没有置信度输出，使用固定值

                # 使用 48px 模型预测颜色
                self._estimate_colors_48px(region_img, q)

                output_regions.append(q)

            except Exception as e:
                self.logger.error(f'[ERROR] Region {idx} OCR failed: {e}')
                q.text = ''
                q.prob = 0.0
                # 设置默认颜色
                q.fg_r = q.fg_g = q.fg_b = 0
                q.bg_r = q.bg_g = q.bg_b = 255
                output_regions.append(q)

            # 清理内存
            self._cleanup_ocr_memory(region_img)

        # 清理 GPU 显存
        if self.use_gpu:
            torch.cuda.empty_cache()

        return output_regions
